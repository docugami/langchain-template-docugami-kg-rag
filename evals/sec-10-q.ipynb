{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC 10-Q Eval\n",
    "\n",
    "Evaluating Docugami KG-RAG against OpenAI Assistants Retrieval for this dataset: https://github.com/docugami/KG-RAG-datasets/tree/main/sec-10-q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp'...\n",
      "remote: Enumerating objects: 119, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 119 (delta 0), reused 9 (delta 0), pack-reused 107\u001b[K\n",
      "Receiving objects: 100% (119/119), 54.88 MiB | 28.79 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf temp\n",
    "!git clone https://github.com/docugami/KG-RAG-datasets.git temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Important: Create your OpenAI assistant via https://platform.openai.com/playground\n",
    "#            and put the assistant ID here. Make sure you upload the identical set of\n",
    "#            files listed below (these files will be uploaded automatically to Docugami)\n",
    "OPENAI_ASSISTANT_ID = \"asst_qY1M0SeFYlmqkEZsMVZX2VAK\"\n",
    "\n",
    "DOCSET_NAME = \"SEC 10Q Filings\"\n",
    "EVAL_NAME = DOCSET_NAME + \" \" + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "FILES_DIR = Path(os.getcwd()) / \"temp/sec-10-q/docs\"\n",
    "FILE_NAMES = [\n",
    "    \"2022 Q3 AAPL.pdf\",\n",
    "    \"2022 Q3 AMZN.pdf\",\n",
    "    \"2022 Q3 INTC.pdf\",\n",
    "    \"2022 Q3 MSFT.pdf\",\n",
    "    \"2022 Q3 NVDA.pdf\",\n",
    "    \"2023 Q1 AAPL.pdf\",\n",
    "    \"2023 Q1 AMZN.pdf\",\n",
    "    \"2023 Q1 INTC.pdf\",\n",
    "    \"2023 Q1 MSFT.pdf\",\n",
    "    \"2023 Q1 NVDA.pdf\",\n",
    "    \"2023 Q2 AAPL.pdf\",\n",
    "    \"2023 Q2 AMZN.pdf\",\n",
    "    \"2023 Q2 INTC.pdf\",\n",
    "    \"2023 Q2 MSFT.pdf\",\n",
    "    \"2023 Q2 NVDA.pdf\",\n",
    "    \"2023 Q3 AAPL.pdf\",\n",
    "    \"2023 Q3 AMZN.pdf\",\n",
    "    \"2023 Q3 INTC.pdf\",\n",
    "    \"2023 Q3 MSFT.pdf\",\n",
    "    \"2023 Q3 NVDA.pdf\",\n",
    "]\n",
    "\n",
    "GROUND_TRUTH_CSV = Path(os.getcwd()) / \"temp/sec-10-q/data/v1/questions_and_answers.csv\"\n",
    "\n",
    "# We will run each experiment multiple times and average, \n",
    "# since results vary slightly over runs\n",
    "PER_EXPERIMENT_RUN_COUNT = 5\n",
    "\n",
    "# Note: Please specify ~6 (or more!) similar files to process together as a document set\n",
    "# This is currently a requirement for Docugami to automatically detect motifs\n",
    "# across the document set to generate a semantic XML Knowledge Graph.\n",
    "assert len(FILE_NAMES) >= 6, \"Please provide at least 6 files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langsmith import Client\n",
    "\n",
    "# Read\n",
    "df = pd.read_csv(GROUND_TRUTH_CSV)\n",
    "\n",
    "# Dataset\n",
    "client = Client()\n",
    "dataset_name = EVAL_NAME\n",
    "existing_datasets = list(client.list_datasets(dataset_name=dataset_name))\n",
    "if existing_datasets:\n",
    "    # read existing dataset\n",
    "    dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "else:\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    # Populate dataset\n",
    "    for _, row in df.iterrows():\n",
    "        q = row[\"Question\"]\n",
    "        a = row[\"Answer\"]\n",
    "        client.create_example(\n",
    "            inputs={\"question\": q}, outputs={\"answer\": a}, dataset_id=dataset.id\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Docugami KG-RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload files to Docugami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docugami import Docugami\n",
    "from docugami.lib.upload import upload_to_named_docset, wait_for_dgml\n",
    "\n",
    "dg_client = Docugami()\n",
    "file_paths = [FILES_DIR / file_name for file_name in FILE_NAMES]\n",
    "\n",
    "# Files will not be re-uploaded if they were previously uploaded (based on name)\n",
    "dg_docs = upload_to_named_docset(dg_client, file_paths, DOCSET_NAME)\n",
    "\n",
    "docset_id = \"\"\n",
    "docset_name = \"\"\n",
    "for doc in dg_docs:\n",
    "    if not docset_id:\n",
    "        docset_id = doc.docset.id\n",
    "    else:\n",
    "        # all docs must be in the same docset\n",
    "        assert docset_id == doc.docset.id\n",
    "\n",
    "    if not docset_name:\n",
    "        docset_name = dg_client.docsets.retrieve(doc.docset.id).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2022 Q3 AAPL.pdf': '/tmp/tmpu0hhgnnq',\n",
       " '2022 Q3 AMZN.pdf': '/tmp/tmp0xkn9_lt',\n",
       " '2022 Q3 INTC.pdf': '/tmp/tmp__wivxrv',\n",
       " '2022 Q3 MSFT.pdf': '/tmp/tmpc0zyvxlc',\n",
       " '2023 Q1 AAPL.pdf': '/tmp/tmpem113lbt',\n",
       " '2023 Q1 AMZN.pdf': '/tmp/tmpr4_mjrf9',\n",
       " '2023 Q1 INTC.pdf': '/tmp/tmpfmox9c0e',\n",
       " '2023 Q1 MSFT.pdf': '/tmp/tmpx51fj_0u',\n",
       " '2023 Q1 NVDA.pdf': '/tmp/tmpn8fl4m8j',\n",
       " '2023 Q2 AAPL.pdf': '/tmp/tmpryvvitdi',\n",
       " '2023 Q2 AMZN.pdf': '/tmp/tmpo80e5vut',\n",
       " '2023 Q2 INTC.pdf': '/tmp/tmp5vgs29hq',\n",
       " '2023 Q2 MSFT.pdf': '/tmp/tmp1mueget7',\n",
       " '2023 Q2 NVDA.pdf': '/tmp/tmp30kowbyg',\n",
       " '2023 Q3 AAPL.pdf': '/tmp/tmpvcmlqzvs',\n",
       " '2023 Q3 AMZN.pdf': '/tmp/tmpcr2kkk24',\n",
       " '2023 Q3 INTC.pdf': '/tmp/tmpsf026dv6',\n",
       " '2023 Q3 MSFT.pdf': '/tmp/tmpi8vfu8zi',\n",
       " '2023 Q3 NVDA.pdf': '/tmp/tmppjj5fdwj',\n",
       " '2022 Q3 NVDA.pdf': '/tmp/tmp7wxepvlx'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for files to finish processing (OCR, and zero-shot creation of XML knowledge graph)\n",
    "\n",
    "# Note: This can take some time on the free docugami tier (up to ~20 mins). Please contact us for faster paid plans.\n",
    "wait_for_dgml(dg_client, dg_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing SEC 10Q Filings (ID: tjwrr2ekqkc3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating full document summaries in batches: 100%|██████████| 2/2 [00:00<00:00, 10.42it/s]\n",
      "Creating chunk summaries in batches: 100%|██████████| 51/51 [00:11<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding documents into chroma for tjwrr2ekqkc3...\n",
      "Done embedding documents into chroma for tjwrr2ekqkc3!\n"
     ]
    }
   ],
   "source": [
    "# Run indexing\n",
    "from docugami_kg_rag.helpers.indexing import index_docset\n",
    "\n",
    "assert docset_id\n",
    "assert docset_name\n",
    "\n",
    "# Note: This can take some time since it is embedding and creating summaries for all the docs and chunks\n",
    "index_docset(docset_id=docset_id, name=docset_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docugami Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from docugami_kg_rag.chain import agent as docugami_agent, _get_tools, AgentInput\n",
    "\n",
    "def predict_docugami_agent(input: dict) -> dict:\n",
    "    question = input[\"question\"]\n",
    "    chain = AgentExecutor(\n",
    "        agent=docugami_agent,\n",
    "        tools=_get_tools(),\n",
    "    ).with_types(\n",
    "        input_type=AgentInput,\n",
    "    )\n",
    "    result = chain.invoke({\n",
    "        \"input\": question,\n",
    "        \"use_reports\": False,\n",
    "        \"chat_history\": [],\n",
    "    })\n",
    "\n",
    "    return result[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Microsoft's operating expenses for the latest quarter, which ended March 31, 2023, increased by $3.6 billion or 26% driven by investments in Azure, 6 points of growth from the Nuance acquisition, and employee severance expenses.\\n\\nSOURCE(S): 2023 Q2 MSFT.pdf\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the agent to make sure it is working\n",
    "predict_docugami_agent({\"question\": \"How much did Microsoft spend for opex in the latest quarter?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OpenAI Assistants Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create OpenAI Agent\n",
    "\n",
    "Please go to https://platform.openai.com/playground and create your agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "\n",
    "def predict_openai_agent(input: dict, config: dict = None) -> dict:\n",
    "    openai_agent = OpenAIAssistantRunnable(assistant_id=OPENAI_ASSISTANT_ID, as_agent=True).with_config(config)\n",
    "    question = input[\"question\"]\n",
    "    result = openai_agent.invoke({\"content\": question})\n",
    "\n",
    "    return result.return_values[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the latest quarter ending September 30, 2023, total operating expenses (opex) amounted to $131.895 billion.\\n\\nSOURCE(S): 2023 Q3 AMZN.pdf【47†source】'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the agent to make sure it is working\n",
    "predict_openai_agent({\"question\": \"How much did Microsoft spend for opex in the latest quarter?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langsmith.client import Client\n",
    "from langchain.smith import RunEvalConfig\n",
    "from langchain.globals import set_llm_cache, get_llm_cache\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"qa\"],\n",
    ")\n",
    "\n",
    "\n",
    "def run_eval(eval_func, eval_run_name):\n",
    "    \"\"\"\n",
    "    Run eval\n",
    "    \"\"\"\n",
    "    client = Client()\n",
    "    client.run_on_dataset(\n",
    "        dataset_name=EVAL_NAME,\n",
    "        llm_or_chain_factory=eval_func,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_name=eval_run_name,\n",
    "        concurrency_level=2,  # Reduced to help with rate limits, but will take longer\n",
    "    )\n",
    "\n",
    "\n",
    "# Experiments\n",
    "agent_map = {\n",
    "    \"docugami_kg_rag_zero_shot\": predict_docugami_agent,\n",
    "    \"openai_assistant_retrieval\": predict_openai_agent,\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Disable global cache setting to get fresh results every time for all experiments\n",
    "    # since no caching or temperature-0 is supported for the openai assistants API and\n",
    "    # we want to measure under similar conditions\n",
    "    cache = get_llm_cache()\n",
    "    set_llm_cache(None)\n",
    "\n",
    "    for i in range(PER_EXPERIMENT_RUN_COUNT):\n",
    "        run_id = str(uuid.uuid4())\n",
    "        for project_name, agent in agent_map.items():\n",
    "            run_eval(agent, project_name + \"_\" + run_id)\n",
    "finally:\n",
    "    # Revert cache setting to global default\n",
    "    set_llm_cache(cache)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-sMPCFT4i-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
